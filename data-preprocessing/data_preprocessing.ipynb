{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../scraper/scraped_data/data_selenium.json\"\n",
    "# Load JSON file\n",
    "with open(file_path) as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>texts</th>\n",
       "      <th>images</th>\n",
       "      <th>pdf_links</th>\n",
       "      <th>pdf_extracted</th>\n",
       "      <th>image_extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.svf.gov.lk/index.php?lang=en</td>\n",
       "      <td>Shrama Vasana Fund - Home</td>\n",
       "      <td>[Menu, About Us, Contributions, Services, Down...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/homeicon.png, h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/homeicon.png':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.svf.gov.lk/index.php?option=com_co...</td>\n",
       "      <td>Shrama Vasana Fund - Overview</td>\n",
       "      <td>[Menu, About Us, Contributions, Services, Down...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/homeicon.png, h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/homeicon.png':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.svf.gov.lk/index.php?option=com_co...</td>\n",
       "      <td>Shrama Vasana Fund - Contributions</td>\n",
       "      <td>[Menu, About Us, Contributions, Services, Down...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/homeicon.png, h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/homeicon.png':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.svf.gov.lk/index.php?option=com_co...</td>\n",
       "      <td>Shrama Vasana Fund - Services</td>\n",
       "      <td>[Menu, About Us, Contributions, Services, Down...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/homeicon.png, h...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/homeicon.png':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.svf.gov.lk/index.php?option=com_co...</td>\n",
       "      <td>Shrama Vasana Fund - Downloads</td>\n",
       "      <td>[Menu, About Us, Contributions, Services, Down...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/homeicon.png, h...</td>\n",
       "      <td>[https://www.svf.gov.lk/images/pdfs/act_en.pdf...</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/pdfs/act_en.pd...</td>\n",
       "      <td>{'https://www.svf.gov.lk/images/homeicon.png':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0           https://www.svf.gov.lk/index.php?lang=en   \n",
       "1  https://www.svf.gov.lk/index.php?option=com_co...   \n",
       "2  https://www.svf.gov.lk/index.php?option=com_co...   \n",
       "3  https://www.svf.gov.lk/index.php?option=com_co...   \n",
       "4  https://www.svf.gov.lk/index.php?option=com_co...   \n",
       "\n",
       "                                title  \\\n",
       "0           Shrama Vasana Fund - Home   \n",
       "1       Shrama Vasana Fund - Overview   \n",
       "2  Shrama Vasana Fund - Contributions   \n",
       "3       Shrama Vasana Fund - Services   \n",
       "4      Shrama Vasana Fund - Downloads   \n",
       "\n",
       "                                               texts  \\\n",
       "0  [Menu, About Us, Contributions, Services, Down...   \n",
       "1  [Menu, About Us, Contributions, Services, Down...   \n",
       "2  [Menu, About Us, Contributions, Services, Down...   \n",
       "3  [Menu, About Us, Contributions, Services, Down...   \n",
       "4  [Menu, About Us, Contributions, Services, Down...   \n",
       "\n",
       "                                              images  \\\n",
       "0  [https://www.svf.gov.lk/images/homeicon.png, h...   \n",
       "1  [https://www.svf.gov.lk/images/homeicon.png, h...   \n",
       "2  [https://www.svf.gov.lk/images/homeicon.png, h...   \n",
       "3  [https://www.svf.gov.lk/images/homeicon.png, h...   \n",
       "4  [https://www.svf.gov.lk/images/homeicon.png, h...   \n",
       "\n",
       "                                           pdf_links  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [https://www.svf.gov.lk/images/pdfs/act_en.pdf...   \n",
       "\n",
       "                                       pdf_extracted  \\\n",
       "0                                                 {}   \n",
       "1                                                 {}   \n",
       "2                                                 {}   \n",
       "3                                                 {}   \n",
       "4  {'https://www.svf.gov.lk/images/pdfs/act_en.pd...   \n",
       "\n",
       "                                     image_extracted  \n",
       "0  {'https://www.svf.gov.lk/images/homeicon.png':...  \n",
       "1  {'https://www.svf.gov.lk/images/homeicon.png':...  \n",
       "2  {'https://www.svf.gov.lk/images/homeicon.png':...  \n",
       "3  {'https://www.svf.gov.lk/images/homeicon.png':...  \n",
       "4  {'https://www.svf.gov.lk/images/homeicon.png':...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Menu',\n",
       " 'About Us',\n",
       " 'Contributions',\n",
       " 'Services',\n",
       " 'Downloads',\n",
       " 'Gallery',\n",
       " 'News & Events',\n",
       " 'Donate Us',\n",
       " 'Vacancy',\n",
       " 'FAQs',\n",
       " 'Contact Us',\n",
       " 'Sitemap',\n",
       " 'About Us',\n",
       " 'Overview',\n",
       " 'Our Team',\n",
       " 'Organisation Structure',\n",
       " 'Gallery',\n",
       " 'Image Gallery',\n",
       " 'Video Gallery',\n",
       " 'Contact Us',\n",
       " 'Inquiry',\n",
       " 'Contact Details',\n",
       " 'සිංහල',\n",
       " 'தமிழ்',\n",
       " 'About Us',\n",
       " 'Overview',\n",
       " 'Our Team',\n",
       " 'Organisation Structure',\n",
       " 'Contributions',\n",
       " 'Services',\n",
       " 'Downloads',\n",
       " 'Gallery',\n",
       " 'Image Gallery',\n",
       " 'Video Gallery',\n",
       " 'News & Events',\n",
       " 'Donate Us',\n",
       " 'Vacancy',\n",
       " 'FAQs',\n",
       " 'Contact Us',\n",
       " 'Inquiry',\n",
       " 'Contact Details',\n",
       " 'Sitemap',\n",
       " 'Health Clinics & Eye Clinics',\n",
       " 'Eye Clinic',\n",
       " 'Empowerment',\n",
       " 'News & Events',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'New',\n",
       " 'Vacancies extended till 2024.04.26',\n",
       " 'prev',\n",
       " 'next',\n",
       " 'Our Services',\n",
       " 'Promotion of the',\n",
       " 'Welfare of the Workers',\n",
       " 'Providing Financial Aid',\n",
       " '& Other Assistance',\n",
       " 'Providing Workers',\n",
       " 'with Medical Aid',\n",
       " 'Temporary Aid',\n",
       " 'to Workers',\n",
       " 'Financial Assistance',\n",
       " '& Other Benefits',\n",
       " 'Presentations in Recognition',\n",
       " 'of Excellent Services',\n",
       " 'Need Our',\n",
       " 'Support?',\n",
       " 'Your',\n",
       " 'Contribution',\n",
       " 'is Appreciated',\n",
       " 'Latest Lottery Results',\n",
       " 'Draw: 416',\n",
       " 'Date: Sunday,',\n",
       " 'September 08, 2024',\n",
       " 'More Results - Lucky 7',\n",
       " 'H',\n",
       " '6',\n",
       " '4',\n",
       " '0',\n",
       " '3',\n",
       " '5',\n",
       " '7',\n",
       " 'View all',\n",
       " 'VIDEO ARCHIVES',\n",
       " 'Click here',\n",
       " 'Related Links',\n",
       " 'National',\n",
       " 'Lotteries Board',\n",
       " 'Law Commission',\n",
       " 'of Sri Lanka',\n",
       " 'NILS - National',\n",
       " 'Institute of',\n",
       " 'Labour Studies',\n",
       " 'National Institute of',\n",
       " 'Occupational Safety',\n",
       " 'and Health',\n",
       " 'Ministry of Labour',\n",
       " 'and Trade Union Relations',\n",
       " 'Department of',\n",
       " 'Labour, Sri Lanka',\n",
       " 'National',\n",
       " 'Lotteries Board',\n",
       " 'Law Commission',\n",
       " 'of Sri Lanka',\n",
       " 'NILS - National',\n",
       " 'Institute of',\n",
       " 'Labour Studies',\n",
       " 'National Institute of',\n",
       " 'Occupational Safety',\n",
       " 'and Health',\n",
       " 'Ministry of Labour',\n",
       " 'and Trade Union Relations',\n",
       " 'Department of',\n",
       " 'Labour, Sri Lanka',\n",
       " 'National',\n",
       " 'Lotteries Board',\n",
       " 'Law Commission',\n",
       " 'of Sri Lanka',\n",
       " 'prev',\n",
       " 'next',\n",
       " 'Home',\n",
       " 'FaLang translation system by Faboba',\n",
       " 'No: 97, Jawatta Road, Colombo 05',\n",
       " '+94 112 588 936',\n",
       " '+94 112 588 937',\n",
       " 'info@svf.gov.lk',\n",
       " 'Copyright © 2024 Shrama Vasana Fund. All Rights Reserved.',\n",
       " 'Design & Developed by',\n",
       " 'Procons Infotech',\n",
       " 'Old Web',\n",
       " 'Last Update:',\n",
       " '09 September 2024.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list_sample = df.loc[0]['texts']\n",
    "text_list_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions for Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['menu', 'home', 'about us', 'contributions', 'services', 'downloads', 'gallery', 'news & events', \n",
    "          'donate us', 'vacancy', 'faqs', 'contact us', 'sitemap', 'shrama vasana fund']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overview', 'Our Team', 'Organisation Structure', 'Image Gallery', 'Video Gallery', 'Inquiry', 'Contact Details', 'සිංහල', 'தமிழ்', 'Health Clinics & Eye Clinics', 'Eye Clinic', 'Empowerment', 'New', 'Vacancies extended till 2024.04.26', 'prev', 'next', 'Our Services', 'Promotion of the', 'Welfare of the Workers', 'Providing Financial Aid', '& Other Assistance', 'Providing Workers', 'with Medical Aid', 'Temporary Aid', 'to Workers', 'Financial Assistance', '& Other Benefits', 'Presentations in Recognition', 'of Excellent Services', 'Need Our', 'Support?', 'Your', 'Contribution', 'is Appreciated', 'Latest Lottery Results', 'Draw: 416', 'Date: Sunday,', 'September 08, 2024', 'More Results - Lucky 7', 'H', '6', '4', '0', '3', '5', '7', 'View all', 'VIDEO ARCHIVES', 'Click here', 'Related Links', 'National', 'Lotteries Board', 'Law Commission', 'of Sri Lanka', 'NILS - National', 'Institute of', 'Labour Studies', 'National Institute of', 'Occupational Safety', 'and Health', 'Ministry of Labour', 'and Trade Union Relations', 'Department of', 'Labour, Sri Lanka', 'FaLang translation system by Faboba', 'No: 97, Jawatta Road, Colombo 05', '+94 112 588 936', '+94 112 588 937', 'info@svf.gov.lk', 'Copyright © 2024 Shrama Vasana Fund. All Rights Reserved.', 'Design & Developed by', 'Procons Infotech', 'Old Web', 'Last Update:', '09 September 2024.']\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(text_list):\n",
    "    '''Remove duplicates and words in remove list from the text list'''\n",
    "    removed = []\n",
    "    for phrase in text_list: \n",
    "        if phrase not in removed:\n",
    "            if phrase.lower() not in remove:\n",
    "                removed.append(phrase)\n",
    "    return removed\n",
    "\n",
    "print(remove_duplicates(text_list_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_texts(text_list): \n",
    "    '''\n",
    "    Does not include stemming and lemmatization, simply cleans the text data\n",
    "    '''\n",
    "    processed = []\n",
    "\n",
    "    for phrase in text_list:\n",
    "        phrase = phrase.strip().lower() # remove spaces and convert to lowercase \n",
    "        phrase = re.sub(r'[^A-Za-z0-9\\s]', '', phrase) # remove special characters and punctuations from text\n",
    "        phrase = re.sub(r'\\n+', ' ', phrase) # replace \\n with space\n",
    "\n",
    "        processed.append(phrase) \n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['menu', 'about us', 'contributions', 'services', 'downloads', 'gallery', 'news  events', 'donate us', 'vacancy', 'faqs', 'contact us', 'sitemap', 'about us', 'overview', 'our team', 'organisation structure', 'gallery', 'image gallery', 'video gallery', 'contact us', 'inquiry', 'contact details', '', '', 'about us', 'overview', 'our team', 'organisation structure', 'contributions', 'services', 'downloads', 'gallery', 'image gallery', 'video gallery', 'news  events', 'donate us', 'vacancy', 'faqs', 'contact us', 'inquiry', 'contact details', 'sitemap', 'health clinics  eye clinics', 'eye clinic', 'empowerment', 'news  events', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'new', 'vacancies extended till 20240426', 'prev', 'next', 'our services', 'promotion of the', 'welfare of the workers', 'providing financial aid', ' other assistance', 'providing workers', 'with medical aid', 'temporary aid', 'to workers', 'financial assistance', ' other benefits', 'presentations in recognition', 'of excellent services', 'need our', 'support', 'your', 'contribution', 'is appreciated', 'latest lottery results', 'draw 416', 'date sunday', 'september 08 2024', 'more results  lucky 7', 'h', '6', '4', '0', '3', '5', '7', 'view all', 'video archives', 'click here', 'related links', 'national', 'lotteries board', 'law commission', 'of sri lanka', 'nils  national', 'institute of', 'labour studies', 'national institute of', 'occupational safety', 'and health', 'ministry of labour', 'and trade union relations', 'department of', 'labour sri lanka', 'national', 'lotteries board', 'law commission', 'of sri lanka', 'nils  national', 'institute of', 'labour studies', 'national institute of', 'occupational safety', 'and health', 'ministry of labour', 'and trade union relations', 'department of', 'labour sri lanka', 'national', 'lotteries board', 'law commission', 'of sri lanka', 'prev', 'next', 'home', 'falang translation system by faboba', 'no 97 jawatta road colombo 05', '94 112 588 936', '94 112 588 937', 'infosvfgovlk', 'copyright  2024 shrama vasana fund all rights reserved', 'design  developed by', 'procons infotech', 'old web', 'last update', '09 september 2024']\n"
     ]
    }
   ],
   "source": [
    "print(process_texts(text_list_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ibm.com/topics/stemming-lemmatization#:~:text=The%20practical%20distinction%20between%20stemming,be%20found%20in%20the%20dictionary.\n",
    "\n",
    "def transform_texts(text_list): \n",
    "    '''\n",
    "    Include stemming and lemmatization for pdf texts where sentence structures should make sense\n",
    "    '''\n",
    "    processed = []\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    for phrase in text_list:\n",
    "        phrase = phrase.strip().lower() # remove spaces and convert to lowercase \n",
    "        phrase = re.sub(r'[^A-Za-z0-9\\s]', '', phrase) # remove special characters and punctuations from text\n",
    "        phrase = re.sub(r'\\n+', ' ', phrase) # replace \\n with space\n",
    "        tokens = word_tokenize(phrase) # tokenise text\n",
    "        tokens = [word for word in tokens if word not in stop_words] # remove stop words\n",
    "        \n",
    "        #stemming\n",
    "        stemming = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "        #lemmatization\n",
    "        lem = [lemmatizer.lemmatize(token) for token in stemming]\n",
    "\n",
    "        processed.append(lem) \n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_text_list(text_list): \n",
    "    '''Tokenise text to feed into lda_model'''\n",
    "    processed = []\n",
    "\n",
    "    for phrase in text_list:\n",
    "        phrase = phrase.strip().lower() # remove spaces and convert to lowercase \n",
    "        phrase = re.sub(r'[^A-Za-z0-9\\s]', '', phrase) # remove special characters and punctuations from text\n",
    "        phrase = re.sub(r'\\n+', ' ', phrase) # replace \\n with space\n",
    "        tokens = word_tokenize(phrase) # tokenise text\n",
    "        \n",
    "        tokens = [word for word in tokens if word not in stop_words] # remove stop words\n",
    "        processed.append(tokens) \n",
    "\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf\n",
    "\n",
    "def topic_modelling(tokenised_text_list):\n",
    "    topic_weights = [] # store topics and weights in a list [(topics, weights)]\n",
    "    texts = tokenise_text_list(tokenised_text_list)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]  \n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=20)\n",
    "    topics = lda_model.print_topics(num_words=1)\n",
    "\n",
    "    for index, topic in topics:\n",
    "        weight_str, topic_str = topic.split(\"*\")\n",
    "        topic = topic_str.replace('\"', '')\n",
    "        weight = float(weight_str)\n",
    "        topic_weights.append((topic, weight))\n",
    "    return topic_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('national', 0.072),\n",
       " ('vacancies', 0.077),\n",
       " ('us', 0.104),\n",
       " ('gallery', 0.077),\n",
       " ('institute', 0.068)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_modelling(text_list_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(phrases_list): \n",
    "    word_count = 0 \n",
    "    for phrase in phrases_list: \n",
    "        word_count += len(phrase.split())\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible entities\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.get_pipe(\"ner\").labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is Us Contributions Services Downloads Gallery News & Events Donate Us Vacancy?', 'Where is Us?', 'What is Contact Us Inquiry Contact Details Sitemap?', 'What is Health Clinics & Eye Clinics Eye Clinic Empowerment News & Events?', 'What is Vacancies?', 'What is Vacancies?', 'What is Vacancies?', 'What is Vacancies?', 'What is Vacancies?', 'What is Vacancies?', 'What is Vacancies?', 'What is 2024.04.26?', 'What is Our Services Promotion?', 'What is Workers Financial Assistance & Other Benefits Presentations?', 'What is Recognition of Excellent Services?', 'What is 416?', 'When did Sunday, September 08, 2024 happen?', 'What is 0?', 'What is Related Links National Lotteries Board Law Commission?', 'What is Sri Lanka NILS - National Institute of Labour Studies National Institute of Occupational Safety and Health Ministry of Labour and Trade Union Relations Department of Labour?', 'What is Sri Lanka National Lotteries Board Law Commission?', 'What is Sri Lanka NILS - National Institute of Labour Studies National Institute of Occupational Safety and Health Ministry of Labour and Trade Union Relations Department of Labour?', 'What is Sri Lanka National Lotteries Board Law Commission?', 'Where is Sri Lanka?', 'What is FaLang?', 'Where is Faboba?', 'What is 97?', 'What is Jawatta Road?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 112?', 'What is 588?', 'What is info@svf.gov.lk?', 'What is 2024?', 'What is Shrama Vasana Fund?', 'When did 09 September 2024 happen?']\n"
     ]
    }
   ],
   "source": [
    "def generate_questions(text):\n",
    "    nlp = spacy.load('en_core_web_sm') # load spacy language model\n",
    "    text = nlp(text) # process text\n",
    "    questions = []\n",
    "    \n",
    "    for entity in text.ents: # look for potential nouns/subjects, generate possible questions with who/where/when/what\n",
    "        if entity.label_ == 'GPE':\n",
    "            question = f\"Where is {entity.text}?\"\n",
    "            questions.append(question) \n",
    "        elif entity.label_ == 'DATE':\n",
    "            question = f\"When did {entity.text} happen?\"\n",
    "            questions.append(question) \n",
    "        elif entity.label == 'PERSON': \n",
    "            question = f\"Who is {entity.text}?\"\n",
    "            questions.append(question) \n",
    "        else: \n",
    "            question = f\"What is {entity.text}?\"\n",
    "            questions.append(question) \n",
    "\n",
    "    return questions\n",
    "\n",
    "questions = generate_questions(\" \".join(text_list_sample))\n",
    "print(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/googletrans/\n",
    "\n",
    "def translate_to_english(text_list):\n",
    "    lst = []\n",
    "    translator = Translator()\n",
    "    for text in text_list:\n",
    "        try:\n",
    "            if text:\n",
    "                translated = translator.translate(text, dest='en')\n",
    "                lst.append(translated.text)\n",
    "            else:\n",
    "                lst.append(\"\")\n",
    "        except Exception as e:\n",
    "            lst.append(\"\") \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_to_english(text):\n",
    "    translator = Translator()\n",
    "    translated  = translator.translate(text , dest='en')\n",
    "    return translated.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_matrix(text_list):\n",
    "    vectorizer = TfidfVectorizer() # general tfidf vectorizer that converts a list of processed texts to a tfidf matrix\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_list)\n",
    "    return tfidf_matrix\n",
    "\n",
    "# print(tfidf_matrix(text_list_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [item['title'] for item in data]\n",
    "texts = [item['texts'] for item in data]\n",
    "pdf_extracted = [item['pdf_extracted'] for item in data]\n",
    "image_extracted = [item['image_extracted'] for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_texts = []\n",
    "for text_list in texts: \n",
    "    text = translate_to_english(text_list)\n",
    "    text = remove_duplicates(text)\n",
    "    text = process_texts(text)\n",
    "    clean_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = []\n",
    "\n",
    "for text_list in clean_texts: \n",
    "    word_count.append(count_words(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_texts = []\n",
    "for i in range(len(image_extracted)):\n",
    "    text = []\n",
    "    for url, image_text in image_extracted[i].items(): \n",
    "        if image_text: \n",
    "            text.append(image_text)\n",
    "    image_texts.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_image_texts = []\n",
    "\n",
    "for text_list in image_texts: \n",
    "    text = translate_to_english(text_list)\n",
    "    text = remove_duplicates(text)\n",
    "    text = process_texts(text)\n",
    "    clean_image_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_texts = []\n",
    "for i in range(len(pdf_extracted)):\n",
    "    text = []\n",
    "    for url, pdf_text in pdf_extracted[i].items(): \n",
    "        text.append(pdf_text)\n",
    "\n",
    "    pdf_texts.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_texts = []\n",
    "for text_list in pdf_texts: \n",
    "    text = translate_to_english(text_list)\n",
    "    text = remove_duplicates(text)\n",
    "    text = transform_texts(text)\n",
    "    clean_pdf_texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_modelling_texts = []\n",
    "\n",
    "for text_list in clean_texts: \n",
    "    topics = topic_modelling(text_list)\n",
    "    topic_modelling_texts.append(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_texts = []\n",
    "\n",
    "for text_list in clean_texts: \n",
    "    tfidf = tfidf_matrix(text_list)\n",
    "    tfidf_texts.append(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['When did 20240426 happen?', 'What is 416?', 'When did 08 2024 happen?', 'What is 7?', 'When did 6 4 happen?', 'What is 0?', 'What is national lotteries board law commission?', 'Where is sri lanka nils?', 'What is health ministry of labour and trade union relations department?', 'What is no 97?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['When did 1998 happen?', 'What is the national lotteries board?', 'What is 1?', 'What is 1?', 'What is 2?', 'What is 2?', 'What is shrama vasana fund?', 'When did 18th dec 2012 happen?', 'When did sunday happen?', 'What is 06?', 'When did march 2010 happen?', 'When did saturday happen?', 'What is jathika sampatha?', 'When did sunday happen?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is 60000?', 'When did 10000 happen?', 'Where is sri lanka?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is tertiary?', 'What is tertiary?', 'What is less than rs 40000?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is shrama vasana fund act no 12?', 'When did 1998 happen?', 'What is 915?', 'What is vasana fund act?', 'When did 2019 happen?', 'When did 2019 happen?', 'When did 13188 happen?', 'What is 695?', 'What is 544?', 'What is 135?', 'What is 448?', 'What is 431?', 'What is 427?', 'What is 439?', 'What is 367?', 'What is 491?', 'What is 551?', 'What is 220?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is 33?', 'When did day 20 happen?', 'What is 21 kurunegala?', 'What is 11?', 'What is 24?', 'When did 2012 happen?', 'What is 3?', 'What is 25?', 'What is 7?', 'What is 5?', 'What is 2?', 'What is 12?', 'What is 50?', 'What is 1?', 'What is 9?', 'What is falang?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is falang?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is 5?', 'What is 25?', 'What is 50 100?', 'When did 20240426 happen?', 'What is no 97?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is tamil?', 'What is 01?', 'What is 02?', 'What is tertiary?', 'What is 03?', 'What is 04?', 'What is 05?', 'What is 06?', 'What is abimana medical?', 'What is shrama abumana medical?', 'What is shrama vasana fund?', 'When did 20000 happen?', 'What is 30000?', 'What is 15000?', 'What is the labor department  labor?', 'What is shrama vasana scholarships?', 'What is shrama vasana program?', 'When did 10000 happen?', 'What is grama niladari?', 'What is falang?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is no 97?', 'What is 05?', 'What is 94 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 16?', 'What is falang?', 'What is google?', 'What is google?', 'What is 05?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is 0112588936?', 'What is 0112588936 ext203?', 'When did 0112588936 happen?', 'When did 0112588936 happen?', 'When did 0112588936 happen?', 'When did 0112588936 happen?', 'What is jaayasinghe 0112588936?', 'When did 0112588936 happen?', 'What is ext0?', 'When did 0112588936 happen?', 'What is 210?', 'When did 0112588936 happen?', 'When did 0112588936 happen?', 'What is one?', 'When did 0112588936 happen?', 'What is falang?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?'], ['What is xmap falang?', 'When did 20240426 happen?', 'What is 05?', 'What is 112?', 'What is 588?', 'What is 936?', 'What is 94 112?', 'What is 588?', 'What is 2024?', 'When did 09 september 2024 happen?']]\n"
     ]
    }
   ],
   "source": [
    "question_texts = []\n",
    "\n",
    "for text_list in clean_texts: \n",
    "    questions = generate_questions(\" \".join(text_list))\n",
    "    question_texts.append(questions)\n",
    "    \n",
    "print(question_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = []\n",
    "for i in range(len(titles)): \n",
    "    combined_data.append({\n",
    "        'title': titles[i],\n",
    "        'texts': clean_texts[i],\n",
    "        'texts_word_count': word_count[i],\n",
    "        'texts_topics': topic_modelling_texts[i],\n",
    "        'texts_questions': question_texts[i],\n",
    "        'texts_tfidf': tfidf_texts[i],\n",
    "        'pdf': clean_pdf_texts[i],\n",
    "        'image': clean_image_texts[i]\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
